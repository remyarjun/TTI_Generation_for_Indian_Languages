# TTI_Malayalam
Implementation of Pytorch for recreating the key results of the TTI_Malayalam and TTI_Hindi models in the paper [Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study](https://link.springer.com/chapter/10.1007/978-3-031-58535-7_12) by Remya Gopalakrishnan and Sudeep P V.

Generalized architectures of the TTI generation models and the images generated by the given models are given below.

* (a) AttnGAN
* (b) DMGAN \cite{Zhuetal2019}
*  (c) DFGAN \cite{Taoetal2022}
*  (d)-(f) The generated images of $64 \times 64$, $128 \times 128$, and $256 \times 256$ resolutions from the respective models.

![Figure1](https://github.com/user-attachments/assets/cbaac273-4ee3-462f-a07b-8e1873cd092e)

## Code Setup

Code is implemented in a local workstation NVIDIA DGX Station A100 Version 5.1.0 and our local machine NVIDIA Quadro RTX 8000.

## Dependencies
* `python 3.6`
* `Pytorch`

In addition, please add the project folder to PYTHONPATH and pip install the following packages while running in local machine:

* `python-dateutil`
* `easydict`
* `pandas`
* `torchfile`
* `nltk`
* `scikit-image`

## Data
Add our preprocessed metadata of bird and coco to your directory and save them to data/.
Download the birds dataset and extract them to data/birds/.
Download coco dataset and extract the images to data/coco/.

## Training
Pre-train encoder models: Use this bird and coco files to train the encoder models.
Train models: Use this bird and coco files for training the models.
*.yml files are example configuration files for training/evaluation our models.

## Pretrained Models
### Encoder

AttnGANGPT, AttnGANBERT, AttnGANXL for bird.
AttnGANGPT for coco.
### Pretrained Models

AttnGANGPT, AttnGANBERT, AttnGANXL for bird.
AttnGANGPT for coco.
## Sampling
For sampling we need to change configurations in cfg file.

To generate images for the pre-extracted embeddings: Set cfg.TRAIN.FLAG = False and cfg.B_VALIDATION = True.

To generate images for custom text input: Set cfg.TRAIN.FLAG = False and cfg.B_VALIDATION = False.

Note If we are using T2I training. We need to add custom examples in example_caption.txt file.

## Validation
We compute inception score for models trained on birds using StackGAN-inception-model.
We compute inception score for models trained on coco using improved-gan/inception_score.

## Sample Results
The below are the exampleimages generated by AttnGAN, DMGAN, and DFGAN models on the Oxford-102 (left), CUB (middle), and COCO (right) datasets.

* The ground truth images for the given captions are listed in the first row
* The images in the remaining rows represent the TTI model results on English, Hindi, and Malayalam captions, respectively.
  
![Figure2](https://github.com/user-attachments/assets/a6f88c3f-037f-48da-9be5-8abdd342200d)

## Creating an API
Evaluation code for bird is configured in this file to generate URL for the API.

## Citing TTI_Malayalam
If you find TTI_Malayalam in your research, please consider citing:
```
@article{
  author    = {R. Gopalakrishnan, P. V. Sudeep},
  title     = {Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study},
  Year      = {2025},
  booktitle = {Sadhana}
}
```

## Reference

AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code](https://github.com/taoxugit/AttnGAN)
DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis [code](https://github.com/MinfengZhu/DM-GAN)
AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code](https://github.com/tobran/DF-GAN)
