# TTI_Malayalam
Implementation of Pytorch for recreating the key results of the TTI_Malayalam and TTI_Hindi models in the paper [Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study](https://link.springer.com) by Remya Gopalakrishnan and Sudeep P V.

Generalized architectures of the TTI generation models and the images generated by the given models are given below.

![Figure1](https://github.com/user-attachments/assets/cbaac273-4ee3-462f-a07b-8e1873cd092e)

## Code Setup

Code is implemented in a local workstation NVIDIA DGX Station A100 Version 5.1.0 and our local machine NVIDIA Quadro RTX 8000.

## Dependencies
* `python 3.6`
* `Pytorch`

In addition, please add the project folder to PYTHONPATH and pip install the following packages while running in local machine:

* `python-dateutil`
* `easydict`
* `pandas`
* `torchfile`
* `nltk`
* `scikit-image`

## Data
* Add our preprocessed metadata of [flower](), [bird](), and [coco]() to your directory and save them to data/.
* Download the [flowers]() dataset and extract them to data/flowers/.
* Download the [birds]() dataset and extract them to data/birds/.
* Download the [coco]() dataset and extract the images to data/coco/.


## Training
* Pre-train encoder models: Use this [flower](), [bird](), and [coco]() files to train the encoder models.
* Train models: Use this [flower](), [bird](), and [coco]() files for training the models.
* *.yml files are example configuration files for training/evaluation our models.

## Pretrained Models
### Encoder

* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `flowers`.
* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `bird`.
* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `coco`.

### Pretrained Models

* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `flowers`.
* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `bird`.
* [DMGAN_Malayalam](), [DMGAN_Hindi]() for `coco`.

## Sampling
* For sampling we need to change configurations in cfg file.

* To generate images for the pre-extracted embeddings: Set `cfg.TRAIN.FLAG = False` and `cfg.B_VALIDATION = True`.

* To generate images for custom text input: Set `cfg.TRAIN.FLAG = False` and `cfg.B_VALIDATION = False`.

**Note** If we are using [T2I training](). We need to add custom examples in example_caption.txt file.

## Validation
* We compute inception score for models trained on birds using [StackGAN-inception-model](https://github.com/hanzhanggit/StackGAN-inception-model).
* We compute inception score for models trained on coco using [improved-gan/inception_score](https://github.com/openai/improved-gan/tree/master/inception_score).

## Sample Results
The below are the exampleimages generated by AttnGAN, DMGAN, and DFGAN models on the Oxford-102 (left), CUB (middle), and COCO (right) datasets.

* The ground truth images for the given captions are listed in the first row
* The images in the remaining rows represent the TTI model results on English, Hindi, and Malayalam captions, respectively.
  
![Figure2](https://github.com/user-attachments/assets/a6f88c3f-037f-48da-9be5-8abdd342200d)

## Creating an API
[Evaluation code]() for `bird` is configured in this file to generate URL for the API.

## Citing TTI_Malayalam
If you find TTI_Malayalam in your research, please consider citing:
```
@article{
  author    = {R. Gopalakrishnan, P. V. Sudeep},
  title     = {Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study},
  Year      = {2025},
  booktitle = {Sadhana}
}
```

## Reference

* [AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code]](https://github.com/taoxugit/AttnGAN)
* [DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis [code]](https://github.com/MinfengZhu/DM-GAN)
* [AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code]](https://github.com/tobran/DF-GAN)
