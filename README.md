# TTI_Malayalam
Implementation of Pytorch for recreating the key results of the TTI_Malayalam and TTI_Hindi models in the paper [Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study](https://link.springer.com/chapter/10.1007/978-3-031-58535-7_12) by Remya Gopalakrishnan and Sudeep P V.



## Code Setup
bird is implemented in google colab.
coco is implemented in our local machine (NVIDIA Quadro RTX 8000).

## Dependencies
python 3.6

Pytorch

In addition, please add the project folder to PYTHONPATH and pip install the following packages while running in local machine:

python-dateutil
easydict
pandas
torchfile
nltk
scikit-image
If using Colab, all the dependencies will be available by default.

## Data
Add our preprocessed metadata of bird and coco to your directory and save them to data/.
Download the birds dataset and extract them to data/birds/.
Download coco dataset and extract the images to data/coco/.

## Training
Pre-train encoder models: Use this bird and coco files to train the encoder models.
Train models: Use this bird and coco files for training the models.
*.yml files are example configuration files for training/evaluation our models.

## Pretrained Models
### Encoder

AttnGANGPT, AttnGANBERT, AttnGANXL for bird.
AttnGANGPT for coco.
### Pretrained Models

AttnGANGPT, AttnGANBERT, AttnGANXL for bird.
AttnGANGPT for coco.
## Sampling
For sampling we need to change configurations in cfg file.

To generate images for the pre-extracted embeddings: Set cfg.TRAIN.FLAG = False and cfg.B_VALIDATION = True.

To generate images for custom text input: Set cfg.TRAIN.FLAG = False and cfg.B_VALIDATION = False.

Note If we are using T2I training. We need to add custom examples in example_caption.txt file.

## Validation
We compute inception score for models trained on birds using StackGAN-inception-model.
We compute inception score for models trained on coco using improved-gan/inception_score.

## Sample Results
The below are the example results with generated image and attention maps of each AttnGANTRANS models for the respective text captions.

The first row in both the results are generated by AttnGANBERT model.
The second row in both the results are generated by AttnGANXL model.
The third row in both the results are generated by AttnGANGPT model.


## Creating an API
Evaluation code for bird is configured in this file to generate URL for the API.

## Citing TTI_Malayalam
If you find TTI_Malayalam in your research, please consider citing:

@article{
  author    = {R. Gopalakrishnan, P. V. Sudeep},
  title     = {Photo-realistic Image Generation using Text Descriptions in Indian Languages: An Exploration Study},
  Year      = {2025},
  booktitle = {{Sadhana}}
}

## Reference

AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code](https://github.com/taoxugit/AttnGAN)
DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis [code](https://github.com/MinfengZhu/DM-GAN)
AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks [code](https://github.com/tobran/DF-GAN)
